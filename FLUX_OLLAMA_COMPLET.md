# ğŸ¨ FLUX COMPLET DE PRÃ‰GÃ‰NÃ‰RATION AVEC OLLAMA

## ğŸ“‹ ARCHITECTURE GLOBALE

```
PDF â†’ Chunks â†’ Embeddings â†’ FAISS â†’ RAG â†’ Ollama â†’ Narrations Uniques (36/Å“uvre)
```

## ğŸ”§ COMPOSANTS DU SYSTÃˆME

### 1. **Extraction et Chunking** (Existant)
- **Fichier**: `model_pdf_processor.py`
- **Fonction**: DÃ©coupe PDF en chunks sÃ©mantiques
- **Table**: `chunk` (chunk_id, oeuvre_id, chunk_text, chunk_order)

### 2. **Embeddings** (Nouveau - PostgreSQL)
- **Fichier**: `core/rag_engine_postgres.py`
- **ModÃ¨le**: `all-MiniLM-L6-v2` (sentence-transformers)
- **Dimension**: 384
- **Table**: `embeddings` (embedding_id, chunk_id, embedding_vector BYTEA)
- **MÃ©thode**: `create_embeddings_for_artwork(oeuvre_id)`

### 3. **Index FAISS** (Nouveau)
- **Fichier**: `core/rag_engine_postgres.py`
- **Type**: `IndexFlatIP` (Inner Product = cosine similarity)
- **Sauvegarde**: `/backend/indexes/museum_postgres/artwork_{id}.faiss` + `.mapping`
- **MÃ©thode**: `build_faiss_index_for_artwork(oeuvre_id)`

### 4. **RAG SÃ©mantique** (Nouveau)
- **Fichier**: `core/rag_engine_postgres.py`
- **Fonction**: Recherche chunks pertinents via similaritÃ© vectorielle
- **ParamÃ¨tres**: `top_k=10`, `threshold=0.1`
- **MÃ©thode**: `search_similar_chunks(query, oeuvre_id)`

### 5. **GÃ©nÃ©ration Ollama** (Nouveau - Anti-hallucination)
- **Fichier**: `core/ollama_generator.py`
- **ModÃ¨le**: Mistral (local via Ollama)
- **URL**: `http://host.docker.internal:11434`
- **TempÃ©rature**: 0.3 (factuel, peu crÃ©atif = moins hallucinations)
- **Top-p**: 0.85 (nucleus sampling strict)
- **MÃ©thode**: `generate_narration(artwork, chunks, rag_context, age, theme, style)`

### 6. **Anti-Hallucination** (Nouveau)
- **Validation post-gÃ©nÃ©ration**:
  - VÃ©rification cohÃ©rence titre/artiste
  - DÃ©tection phrases spÃ©culatives ("on raconte que", "probablement")
  - Validation longueur (30-600 mots)
  - VÃ©rification lien avec contexte RAG (>5 mots communs)
- **Fallback sÃ©curisÃ©** si validation Ã©choue

### 7. **Orchestration ComplÃ¨te** (Nouveau)
- **Fichier**: `core/ollama_pregeneration_complete.py`
- **Flux par Å“uvre**:
  1. Setup RAG (embeddings + FAISS)
  2. RÃ©cupÃ©ration contexte RAG
  3. GÃ©nÃ©ration 36 narrations (4 ages Ã— 3 thÃ¨mes Ã— 3 styles)
  4. Sauvegarde BDD
- **MÃ©thode**: `pregenerate_artwork(oeuvre_id, force_regenerate)`

## ğŸš€ API ENDPOINTS

### **POST /api/pregenerate-artwork/:id**
PrÃ©gÃ©nÃ©ration complÃ¨te pour UNE Å“uvre
```json
{
  "force_regenerate": false,
  "skip_rag_setup": false
}
```

**RÃ©ponse**:
```json
{
  "success": true,
  "oeuvre_id": 1,
  "title": "La Joconde",
  "stats": {
    "generated": 36,
    "updated": 0,
    "skipped": 0,
    "errors": 0
  },
  "duration": 42.5
}
```

### **POST /api/pregenerate-all**
PrÃ©gÃ©nÃ©ration pour TOUTES les Å“uvres
```json
{
  "force_regenerate": false
}
```

### **POST /api/rag/embeddings/create/:id**
CrÃ©er embeddings pour une Å“uvre

### **POST /api/rag/faiss/build/:id**
Construire index FAISS pour une Å“uvre

### **POST /api/rag/search**
Recherche sÃ©mantique dans les chunks
```json
{
  "query": "technique peinture",
  "oeuvre_id": 1,
  "top_k": 5
}
```

## ğŸ“Š PROFILS DE GÃ‰NÃ‰RATION (36 combinaisons)

### **Ages (4):**
- `enfant`: Vocabulaire simple, phrases courtes
- `ado`: Accessible, engageant
- `adulte`: Standard, informatif
- `senior`: Enrichi, contexte historique

### **ThÃ©matiques (3):**
- `technique_picturale`: Focus matÃ©riaux/technique
- `biographie`: Focus artiste/vie
- `historique`: Focus contexte/Ã©poque

### **Styles (3):**
- `analyse`: Analytique, structurÃ©
- `decouverte`: Progressif, dÃ©couverte
- `anecdote`: Narratif mais factuel

## ğŸ”„ WORKFLOW COMPLET

```
1. UPLOAD PDF
   â†“
2. EXTRACTION MÃ‰TADONNÃ‰ES (model_pdf_processor.py)
   â†“
3. CHUNKING (model_pdf_processor.py)
   â†’ Table: chunk
   â†“
4. EMBEDDINGS (rag_engine_postgres.py)
   â†’ ModÃ¨le: all-MiniLM-L6-v2
   â†’ Table: embeddings (BYTEA pickle)
   â†“
5. INDEX FAISS (rag_engine_postgres.py)
   â†’ Fichiers: .faiss + .mapping
   â†’ Type: IndexFlatIP
   â†“
6. RAG CONTEXT (rag_engine_postgres.py)
   â†’ Recherche top 10 chunks pertinents
   â†’ Seuil: 0.1
   â†“
7. GÃ‰NÃ‰RATION OLLAMA (ollama_generator.py)
   â†’ Prompt anti-hallucination
   â†’ TempÃ©rature: 0.3
   â†’ Top-p: 0.85
   â†“
8. VALIDATION (ollama_generator.py)
   â†’ VÃ©rification factuelle
   â†’ DÃ©tection spÃ©culations
   â†’ Fallback si suspect
   â†“
9. SAUVEGARDE BDD
   â†’ Table: pregeneration
   â†’ 36 narrations/Å“uvre
```

## âš™ï¸ CONFIGURATION OLLAMA

### **Installation Ollama (Windows)**
```powershell
# TÃ©lÃ©charger: https://ollama.com/download
# Installer Ollama Desktop

# VÃ©rifier
ollama --version

# Pull modÃ¨le Mistral
ollama pull mistral
```

### **Variables d'environnement**
```env
OLLAMA_API_URL=http://host.docker.internal:11434
OLLAMA_MODEL=mistral
```

### **VÃ©rifier disponibilitÃ©**
```powershell
curl http://localhost:11434/api/tags
```

## ğŸ³ DOCKER

### **Build Backend**
```bash
docker-compose build backend
```

### **Start Services**
```bash
docker-compose up -d
```

### **Logs Backend**
```bash
docker logs museum-backend -f
```

## ğŸ“ˆ PERFORMANCE

### **Optimisations implÃ©mentÃ©es:**
1. **Cache Docker multi-stage** â†’ Build 5x plus rapide
2. **Torch CPU-only** â†’ -60% taille image
3. **Sentence-transformers preload** â†’ -30s dÃ©marrage
4. **FAISS IndexFlatIP** â†’ Recherche <10ms
5. **Ollama tempÃ©rature basse** â†’ Moins hallucinations, plus rapide
6. **Singleton RAG engine** â†’ Pas de reload modÃ¨le

### **Benchmarks typiques:**
- **Embeddings** (1 Å“uvre, 20 chunks): ~2-3s
- **FAISS build**: ~0.5s
- **RAG search** (top 10): ~10ms
- **Ollama gÃ©nÃ©ration** (1 narration): ~5-15s (selon hardware)
- **36 narrations complÃ¨tes**: ~3-8 min/Å“uvre

## ğŸ”’ SÃ‰CURITÃ‰ ANTI-HALLUCINATION

### **Prompts stricts:**
```
RÃˆGLES ABSOLUES:
- N'invente AUCUNE information
- N'ajoute AUCUN dÃ©tail qui n'est pas dans le contexte
- Si tu ne sais pas, ne spÃ©cule pas
- Reste STRICTEMENT factuel
```

### **Validation post-gÃ©nÃ©ration:**
- âŒ DÃ©tection "on raconte que", "probablement"
- âœ… VÃ©rification lien avec contexte source
- âœ… CohÃ©rence titre/artiste
- âœ… Longueur raisonnable (30-600 mots)

### **Fallback automatique:**
Si validation Ã©choue â†’ GÃ©nÃ©ration factuelle pure Ã  partir des mÃ©tadonnÃ©es

## ğŸ“± DASHBOARD

### **Bouton "GÃ©nÃ©rer narrations Ollama"**
- Lance `/api/pregenerate-artwork/:id`
- Affiche progression temps rÃ©el
- Stats: gÃ©nÃ©rÃ©es/mises Ã  jour/erreurs

### **Indicateurs RAG:**
- âœ… Embeddings crÃ©Ã©s
- âœ… Index FAISS construit
- âœ… Narrations gÃ©nÃ©rÃ©es (36/36)

## ğŸ§ª TESTS

### **Test embeddings:**
```bash
curl -X POST http://localhost:5000/api/rag/embeddings/create/1
```

### **Test FAISS:**
```bash
curl -X POST http://localhost:5000/api/rag/faiss/build/1
```

### **Test recherche RAG:**
```bash
curl -X POST http://localhost:5000/api/rag/search \
  -H "Content-Type: application/json" \
  -d '{"query":"technique peinture","oeuvre_id":1,"top_k":5}'
```

### **Test prÃ©gÃ©nÃ©ration:**
```bash
curl -X POST http://localhost:5000/api/pregenerate-artwork/1 \
  -H "Content-Type: application/json" \
  -d '{"force_regenerate":true}'
```

## ğŸ› TROUBLESHOOTING

### **Ollama non disponible**
```
âš ï¸ ATTENTION: Ollama non disponible - Fallback automatique activÃ©
```
â†’ VÃ©rifier Ollama Desktop dÃ©marrÃ©
â†’ VÃ©rifier port 11434 accessible

### **Embeddings lents**
â†’ Normal au premier lancement (tÃ©lÃ©chargement modÃ¨le)
â†’ Puis ~2-3s par Å“uvre

### **Narrations gÃ©nÃ©riques**
â†’ VÃ©rifier chunks extraits (non vides)
â†’ VÃ©rifier RAG context (>100 caractÃ¨res)
â†’ VÃ©rifier tempÃ©rature Ollama (<0.5)

### **Erreur FAISS**
â†’ VÃ©rifier embeddings crÃ©Ã©s d'abord
â†’ VÃ©rifier permissions dossier `/app/indexes`

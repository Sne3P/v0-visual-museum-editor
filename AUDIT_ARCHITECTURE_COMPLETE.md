# üîç AUDIT COMPLET - ARCHITECTURE & PIPELINE G√âN√âRATION NARRATIONS

**Date**: 5 Janvier 2026  
**Version**: 1.0  
**Statut**: ‚úÖ ARCHITECTURE VALIDE avec optimisations recommand√©es

---

## üìä R√âSUM√â EX√âCUTIF

### ‚úÖ **VERDICT: BONNE STRAT√âGIE, SCALABLE, QUELQUES OPTIMISATIONS POSSIBLES**

Votre architecture **chunks + embeddings + FAISS + RAG + LLM** est:
- ‚úÖ **Correcte et standard** pour la g√©n√©ration contextuelle
- ‚úÖ **Scalable** pour plusieurs mus√©es
- ‚úÖ **Bien structur√©e** (s√©paration concerns, cascades DB propres)
- ‚ö†Ô∏è **Optimisable** (r√©utilisation contexte, parall√©lisation, caching)

**Points forts majeurs**:
1. S√©paration chunks/embeddings/FAISS = r√©utilisable
2. Pregenerations avec UNIQUE constraint = pas de doublons
3. Cascades ON DELETE = pas d'orphelins
4. force_regenerate = contr√¥le total sur r√©g√©n√©ration

**Optimisations recommand√©es** (d√©tails ci-dessous):
1. **Batch contexte RAG** une seule fois pour 36 narrations (gain ~30%)
2. **Parall√©lisation Ollama** (8 threads ‚Üí 36 narrations simultan√©es, gain ~70%)
3. **Cache prompts** par th√©matique (r√©utilisation base)
4. **Embeddings batch** (cr√©er tous d'un coup vs 1 par 1)

---

## üèóÔ∏è ANALYSE ARCHITECTURE

### 1. **STRAT√âGIE CHUNKS + EMBEDDINGS + FAISS**

#### ‚úÖ CE QUI EST BIEN:

**A. Cr√©ation chunks s√©mantiques**
```python
# chunk_creator_postgres.py - Structure optimis√©e
CHUNK 0: M√âTADONN√âES ESSENTIELLES (titre, artiste, date, technique)
CHUNK 1: CONTEXTE HISTORIQUE & COMMANDE (1200 chars max)
CHUNK 2: DESCRIPTION & CONTEXTE ARTISTIQUE
CHUNK 3: ANALYSE TECHNIQUE & MAT√âRIELLE
CHUNK 4: ICONOGRAPHIE & SYMBOLIQUE
CHUNK 5: R√âCEPTION CRITIQUE & POST√âRIT√â
CHUNK 6: CONSERVATION & DOCUMENTATION
CHUNK 7: PROVENANCE
```

**Avantages**:
- ‚úÖ **S√©mantique claire**: Chaque chunk = 1 th√©matique pr√©cise
- ‚úÖ **Labels explicites**: "CONTEXTE HISTORIQUE" vs "Contexte" (meilleur pour RAG)
- ‚úÖ **Limite 1200 chars**: Optimal pour embeddings (ni trop court, ni trop long)
- ‚úÖ **Fallback**: Minimum 2 chunks m√™me si m√©tadonn√©es incompl√®tes
- ‚úÖ **Index**: chunk_index pour ordre pr√©serv√©

**Pourquoi c'est pertinent**:
- Embeddings SentenceTransformer fonctionnent mieux avec chunks 200-1500 chars
- Th√©matiques s√©par√©es = meilleur matching RAG (technique vs biographie)
- Permet recherche pr√©cise ("technique picturale" ‚Üí chunk 3, "historique" ‚Üí chunk 1)

#### ‚úÖ B. Embeddings & FAISS

**Configuration actuelle**:
```python
# rag_engine_postgres.py
model_name = "all-MiniLM-L6-v2"  # 384 dimensions
index = faiss.IndexFlatIP(dimension)  # Inner Product = cosine similarity
faiss.normalize_L2(vectors)  # Normalisation pour cosine
```

**Avantages**:
- ‚úÖ **Mod√®le l√©ger**: all-MiniLM-L6-v2 = 80MB, rapide CPU
- ‚úÖ **Cosine similarity**: Meilleure mesure pour texte s√©mantique
- ‚úÖ **1 index par ≈ìuvre**: Isolation propre, pas de pollution entre ≈ìuvres
- ‚úÖ **Sauvegarde disque**: .faiss + .mapping = persistance
- ‚úÖ **Normalisation L2**: Obligatoire pour cosine avec IndexFlatIP

**Pourquoi c'est pertinent**:
- FAISS = recherche vectorielle ultra-rapide (ms vs sec avec distance naive)
- Index s√©par√© par ≈ìuvre = r√©g√©n√©ration facile (pas besoin rebuild global)
- Cosine = ind√©pendant de la longueur (focus sur similarit√© s√©mantique)

#### ‚ö†Ô∏è CE QUI PEUT √äTRE AM√âLIOR√â:

**A. Batch embeddings creation**
```python
# ACTUEL (rag_engine_postgres.py:102-135)
for chunk in chunks:
    embedding_vector = self.model.encode(chunk_text, convert_to_numpy=True)
    # INSERT 1 par 1
```

**‚ùå Probl√®me**: 1 appel model.encode() par chunk = lent (setup/teardown overhead)

**‚úÖ SOLUTION: Batch encoding**
```python
def create_embeddings_batch(self, oeuvre_id: int):
    chunks = get_artwork_chunks(oeuvre_id)
    chunk_texts = [c['chunk_text'] for c in chunks]
    
    # 1 seul appel pour tous les chunks
    all_embeddings = self.model.encode(chunk_texts, batch_size=32, convert_to_numpy=True)
    
    # Puis INSERT en batch
    values = [(chunk_id, pickle.dumps(emb), ...) for chunk_id, emb in zip(chunk_ids, all_embeddings)]
    cur.executemany("INSERT INTO embeddings ...", values)
```

**Gain estim√©**: 30-50% plus rapide (5-8 chunks = 1 seul forward pass neural net)

**B. Cache contexte RAG**
```python
# ACTUEL (ollama_pregeneration_complete.py:88-92)
rag_context = self._build_artwork_rag_context(oeuvre_id, chunks)

# Puis pour CHAQUE narration (√ó36):
for age, theme, style:
    narration = ollama_gen.generate_narration(
        rag_context=rag_context,  # MEME contexte r√©utilis√© ‚úÖ
        ...
    )
```

**‚úÖ D√©j√† correct**: Contexte RAG cr√©√© 1√ó et r√©utilis√© 36√ó

**üí° AM√âLIORATION POSSIBLE**: Filtrer chunks par th√©matique
```python
def _build_filtered_context(self, chunks, thematique):
    """S√©lectionne chunks pertinents selon th√©matique"""
    if thematique == 'technique_picturale':
        # Prioriser chunk 3 (ANALYSE TECHNIQUE) + chunk 0 (M√âTADONN√âES)
        return chunks[0] + chunks[3] if len(chunks) > 3 else all_chunks
    elif thematique == 'biographie':
        # Prioriser chunk 2 (CONTEXTE ARTISTIQUE) + chunk 1 (HISTORIQUE)
        return chunks[0] + chunks[1] + chunks[2]
    elif thematique == 'historique':
        return chunks[0] + chunks[1] + chunks[5]  # + R√âCEPTION
```

**Avantage**: Contexte plus pr√©cis = meilleure g√©n√©ration (moins de bruit)
**Inconv√©nient**: Plus complexe, risque de manquer info importante
**Recommandation**: **Garder contexte complet actuel** (plus s√ªr), MAIS ajouter weights dans prompt

---

### 2. **SCALABILIT√â MULTI-MUS√âES**

#### ‚úÖ ARCHITECTURE MULTI-TENANT READY

**S√©paration par plan_id**:
```sql
-- Chaque mus√©e = 1 plan_id
plans (plan_id, nom, description)
  ‚Üì
entities (entity_id, plan_id, oeuvre_id)  -- FK plan_id
  ‚Üì
oeuvres (oeuvre_id, title, artist, ...)

-- Chunks/embeddings/pregenerations li√©s √† oeuvre_id uniquement
chunk (chunk_id, oeuvre_id)
embeddings (embedding_id, chunk_id)
pregenerations (pregeneration_id, oeuvre_id, age_cible, thematique, style_texte)
```

**‚úÖ Points forts**:
1. **Isolation plan**: Chaque mus√©e = 1 plan, g√©om√©trie s√©par√©e
2. **Partage ≈ìuvres**: ≈íuvres partag√©es entre plans (ex: Mona Lisa dans plusieurs mus√©es)
3. **Pas de duplication RAG**: Chunks/embeddings/narrations par oeuvre_id (pas plan_id)
4. **R√©utilisation**: Si 2 mus√©es ont m√™me ≈ìuvre ‚Üí m√™me pregenerations r√©utilisables

**üí° RECOMMANDATIONS SCALABILIT√â**:

**A. Ajouter champ museum_id (optionnel mais recommand√©)**
```sql
ALTER TABLE plans ADD COLUMN museum_id INTEGER;
ALTER TABLE oeuvres ADD COLUMN museum_id INTEGER;

-- Pour filtrage facile:
SELECT * FROM oeuvres WHERE museum_id = 1;
SELECT * FROM pregenerations WHERE oeuvre_id IN (SELECT oeuvre_id FROM oeuvres WHERE museum_id = 1);
```

**B. Index FAISS global optionnel**
```python
# Actuellement: 1 index FAISS par ≈ìuvre
# artwork_1.faiss, artwork_2.faiss, ...

# Pour recherche cross-≈ìuvres (futur):
# museum_1_global.faiss (toutes ≈ìuvres du mus√©e 1)
```

**Avantage**: Recherche "tableaux impressionnistes dans tout le mus√©e"  
**Pour l'instant**: Pas n√©cessaire (chaque narration = 1 ≈ìuvre sp√©cifique)

**C. Param√®tres mus√©e-sp√©cifiques**
```sql
CREATE TABLE museum_settings (
    museum_id SERIAL PRIMARY KEY,
    nom TEXT,
    ages_cibles TEXT[],  -- ['enfant', 'ado', 'adulte', 'senior']
    thematiques TEXT[],  -- Customizable par mus√©e
    styles TEXT[],
    ollama_temperature REAL DEFAULT 0.2,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

**Utilisation**:
```python
# Actuellement hardcod√©:
self.ages = ['enfant', 'ado', 'adulte', 'senior']

# Version future:
settings = get_museum_settings(museum_id)
self.ages = settings['ages_cibles']  # Configurable!
```

**‚úÖ VERDICT SCALABILIT√â**: Tr√®s bien structur√©, pr√™t pour multi-mus√©es

---

## üîÑ AUDIT PIPELINE COMPL√àTE

### **FLUX COMPLET: Plan ‚Üí ≈íuvres ‚Üí PDF ‚Üí Chunks ‚Üí Embeddings ‚Üí FAISS ‚Üí Narrations**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ √âTAPE 1: CR√âATION PLAN & ≈íUVRES (Frontend ‚Üí save-to-db)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
1. User cr√©e plan dans √©diteur
2. User ajoute artworks (upload PDF optionnel)
3. Click "Sauvegarder"
4. Frontend: database.service.ts ‚Üí exportData
5. API: POST /api/save-to-db
6. DB: UPSERT oeuvres (ON CONFLICT = update, sinon insert)

‚úÖ CORRECT:
- Pas de chunks cr√©√©s frontend (pollution supprim√©e)
- ON CONFLICT = pas de doublons
- M√©tadonn√©es PDF extraites et sauvegard√©es

‚ö†Ô∏è ATTENTION:
- TRUNCATE chunk CASCADE (ligne 86) = SUPPRIME TOUS CHUNKS √Ä CHAQUE SAVE
- Probl√®me: Si user save plan ‚Üí chunks r√©g√©n√©r√©s inutilement

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ √âTAPE 2: EXTRACTION PDF (Optionnel)                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
1. User upload PDF via frontend
2. API: POST /api/extract-pdf-metadata
3. Backend: /api/pdf/extract-metadata (PyPDF2)
4. M√©tadonn√©es ‚Üí oeuvres table (update)

‚úÖ CORRECT:
- Extraction m√©tadonn√©es propre
- Sauvegarde dans colonnes d√©di√©es (contexte_commande, iconographie, etc.)

‚ö†Ô∏è NOTE:
- Chunks PAS cr√©√©s ici (bon!)
- Chunks cr√©√©s uniquement au clic "G√©n√©rer"

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ √âTAPE 3: G√âN√âRATION NARRATIONS (Dashboard ‚Üí pregenerate)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
1. User: Click "G√©n√©rer" pour 1 ≈ìuvre
2. API: POST /api/admin/pregenerate-artwork/[oeuvreId]
3. Backend: ollama_pregeneration_complete.py

SUB-√âTAPE 3.1: SETUP RAG
‚îú‚îÄ chunk_creator_postgres.py
‚îÇ  ‚îú‚îÄ DELETE FROM chunk WHERE oeuvre_id = X  ‚Üê Supprime anciens
‚îÇ  ‚îú‚îÄ Cr√©e 5-8 chunks s√©mantiques
‚îÇ  ‚îî‚îÄ INSERT INTO chunk (chunk_text, chunk_index, oeuvre_id)
‚îÇ
‚îú‚îÄ rag_engine_postgres.py ‚Üí create_embeddings_for_artwork()
‚îÇ  ‚îú‚îÄ Pour chaque chunk: model.encode(chunk_text)
‚îÇ  ‚îú‚îÄ Normalisation L2
‚îÇ  ‚îî‚îÄ INSERT INTO embeddings (chunk_id, embedding_vector)
‚îÇ
‚îî‚îÄ rag_engine_postgres.py ‚Üí build_faiss_index_for_artwork()
   ‚îú‚îÄ SELECT embeddings JOIN chunk WHERE oeuvre_id = X
   ‚îú‚îÄ Cr√©er IndexFlatIP (dimension=384)
   ‚îú‚îÄ Sauvegarder artwork_X.faiss + artwork_X.mapping
   ‚îî‚îÄ Return success

SUB-√âTAPE 3.2: G√âN√âRATION 36 NARRATIONS
‚îú‚îÄ Pour chaque (age, theme, style):  # 4√ó3√ó3 = 36
‚îÇ  ‚îú‚îÄ RAG search (top-5 chunks via FAISS)  ‚Üê PAS FAIT ACTUELLEMENT!
‚îÇ  ‚îú‚îÄ Build contexte (concatenate chunks)
‚îÇ  ‚îú‚îÄ Build prompt factuel (ollama_generator_improved.py)
‚îÇ  ‚îú‚îÄ Call Ollama (temperature=0.2, CPU-only)
‚îÇ  ‚îú‚îÄ Validation stricte (anti-hallucination)
‚îÇ  ‚îî‚îÄ INSERT INTO pregenerations (ON CONFLICT DO UPDATE)
‚îÇ
‚îî‚îÄ Return stats (generated, updated, errors)

‚úÖ CORRECT:
- Chunks r√©g√©n√©r√©s √† chaque fois (force_regenerate)
- Embeddings r√©g√©n√©r√©s (coh√©rence garantie)
- FAISS rebuild (index toujours √† jour)
- Pregenerations avec UNIQUE constraint (pas doublons)
- ON CONFLICT DO UPDATE = √©crasement safe

‚ö†Ô∏è PROBL√àME MAJEUR IDENTIFI√â:
```python
# ollama_generator_improved.py:66
def generate_narration(self, artwork, chunks, rag_context, ...):
    # rag_context = string concat√©n√© de TOUS les chunks
    # PAS de recherche FAISS!
```

**‚ùå FAISS INDEX PAS UTILIS√â POUR LA G√âN√âRATION!**

Le code cr√©e l'index FAISS mais ne l'utilise pas:
- _build_artwork_rag_context() = concat√®ne TOUS les chunks
- Pas de search_similar_chunks() appel√©
- FAISS = juste sauvegard√©, jamais interrog√©

**Impact**: Contexte RAG = tous les chunks (OK pour 5-8 chunks, mais inefficace si >20)

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ √âTAPE 4: G√âN√âRATION PARCOURS (Futur)                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
1. User s√©lectionne ≈ìuvres + crit√®res (age, theme, style)
2. API: /api/generate-parcours
3. R√©cup√®re pregenerations matching crit√®res
4. Cr√©e parcours avec timings (walking 0.5m/s, narration 90wpm)
5. Return parcours JSON

‚úÖ CORRECT:
- Pregenerations d√©j√† g√©n√©r√©es = instant
- Pas de LLM call = rapide
```

---

## üóÑÔ∏è AUDIT DATABASE INTEGRITY

### **A. CASCADES ON DELETE**

```sql
-- ‚úÖ BIEN CONFIGUR√â:

1. plans ‚Üí entities: ON DELETE CASCADE
   Si plan supprim√© ‚Üí toutes entities supprim√©es

2. entities ‚Üí points: ON DELETE CASCADE
   Si entity supprim√©e ‚Üí tous points supprim√©s

3. entities ‚Üí relations: ON DELETE CASCADE
   Si entity supprim√©e ‚Üí toutes relations supprim√©es

4. oeuvres ‚Üí chunk: ON DELETE CASCADE
   Si oeuvre supprim√©e ‚Üí tous chunks supprim√©s

5. chunk ‚Üí embeddings: ON DELETE CASCADE
   Si chunk supprim√© ‚Üí tous embeddings supprim√©s

6. oeuvres ‚Üí pregenerations: ON DELETE CASCADE
   Si oeuvre supprim√©e ‚Üí toutes pregenerations supprim√©es

7. oeuvres ‚Üí sections: ON DELETE CASCADE

8. oeuvres ‚Üí anecdotes: ON DELETE CASCADE
```

**‚úÖ R√âSULTAT**: Pas d'orphelins possibles, cascades propres

### **B. GESTION ORPHELINS**

**save-to-db/route.ts (lines 69-79)**:
```typescript
DELETE FROM oeuvres
WHERE oeuvre_id NOT IN (SELECT DISTINCT oeuvre_id FROM entities WHERE oeuvre_id IS NOT NULL)
AND oeuvre_id NOT IN (SELECT DISTINCT oeuvre_id FROM pregenerations WHERE oeuvre_id IS NOT NULL)
```

**‚úÖ LOGIQUE**: Supprime ≈ìuvres orphelines SAUF si pregenerations existent (protection LLM content)

**‚ö†Ô∏è PROBL√àME IDENTIFI√â**:

```typescript
// Ligne 86
await client.query('TRUNCATE TABLE points, relations, entities, plans, chunk CASCADE')
```

**‚ùå TRUNCATE chunk CASCADE = SUPPRIME TOUS LES CHUNKS + EMBEDDINGS √Ä CHAQUE SAVE!**

**Impact**:
1. User save plan (m√™me sans changement ≈ìuvres)
2. ‚Üí TOUS chunks/embeddings supprim√©s
3. ‚Üí Reg√©n√©ration compl√®te n√©cessaire (3-5 min par ≈ìuvre)

**Solution recommand√©e**:
```typescript
// NE PAS truncate chunk si oeuvres pas modifi√©es
await client.query('TRUNCATE TABLE points, relations, entities, plans CASCADE')

// Supprimer chunks UNIQUEMENT pour ≈ìuvres modifi√©es/supprim√©es
// Les chunks sont d√©j√† g√©r√©s par force_regenerate lors du clic "G√©n√©rer"
```

**Logique am√©lior√©e**:
- Chunks cr√©√©s UNIQUEMENT au clic "G√©n√©rer narrations"
- Save plan = ne touche PAS aux chunks
- Force_regenerate = contr√¥le explicite de r√©g√©n√©ration

### **C. UNIQUE CONSTRAINTS**

```sql
-- ‚úÖ BIEN:
pregenerations (oeuvre_id, age_cible, thematique, style_texte) UNIQUE

-- Emp√™che doublons, permet ON CONFLICT DO UPDATE

-- ‚úÖ BIEN:
embeddings (chunk_id, model_name) UNIQUE

-- Permet changer de mod√®le embeddings sans conflit
```

### **D. INDEXES**

```sql
-- ‚úÖ BIEN:
CREATE INDEX idx_pregenerations_oeuvre ON pregenerations(oeuvre_id);
CREATE INDEX idx_pregenerations_criteres ON pregenerations(age_cible, thematique, style_texte);
CREATE INDEX idx_sections_oeuvre ON sections(oeuvre_id);
CREATE INDEX idx_anecdotes_oeuvre ON anecdotes(oeuvre_id);
CREATE INDEX idx_oeuvres_artiste ON oeuvres(artiste_id);
CREATE INDEX idx_oeuvres_mouvement ON oeuvres(mouvement_id);
```

**üí° RECOMMANDATION: Ajouter index chunk**
```sql
CREATE INDEX idx_chunk_oeuvre ON chunk(oeuvre_id);
CREATE INDEX idx_embeddings_chunk ON embeddings(chunk_id);
```

**Justification**: Acc√©l√®re requ√™tes RAG (SELECT chunks WHERE oeuvre_id = X)

---

## ‚ö° OPTIMISATIONS G√âN√âRATION

### **1. PARALL√âLISATION 36 NARRATIONS**

**ACTUEL (s√©quentiel)**:
```python
for age in self.ages:         # 4
    for theme in self.themes: # 3
        for style in self.styles:  # 3
            narration = ollama_gen.generate_narration(...)  # 5-10 sec
            # Total: 36 √ó 8s = 288 sec (4.8 min)
```

**‚úÖ OPTIMISATION: ThreadPoolExecutor**
```python
from concurrent.futures import ThreadPoolExecutor, as_completed

def pregenerate_artwork_parallel(self, oeuvre_id, force_regenerate):
    # Pr√©parer RAG 1√ó (partag√©)
    chunks = get_artwork_chunks(oeuvre_id)
    rag_context = self._build_artwork_rag_context(oeuvre_id, chunks)
    
    # Cr√©er toutes les combinaisons
    tasks = [
        (age, theme, style)
        for age in self.ages
        for theme in self.themes
        for style in self.styles
    ]
    
    def generate_one(task):
        age, theme, style = task
        narration = self.ollama_gen.generate_narration(
            artwork=artwork,
            chunks=chunks,
            rag_context=rag_context,  # R√©utilis√© (thread-safe)
            age_cible=age,
            thematique=theme,
            style_texte=style
        )
        return (age, theme, style, narration)
    
    # Parall√©liser avec 8 workers (CPU threads)
    results = []
    with ThreadPoolExecutor(max_workers=8) as executor:
        futures = [executor.submit(generate_one, task) for task in tasks]
        for future in as_completed(futures):
            results.append(future.result())
    
    # Sauvegarder tous en batch
    for age, theme, style, narration in results:
        add_pregeneration(oeuvre_id, age, theme, style, narration)
```

**Gain estim√©**:
- Actuel: 36 √ó 8s = 288s (4.8 min)
- Avec 8 workers: 36 / 8 √ó 8s = 36s (~70% plus rapide!)

**‚ö†Ô∏è ATTENTION OLLAMA**:
- Ollama peut limiter concurrent requests (v√©rifier config)
- Si timeout, r√©duire max_workers √† 4

### **2. CACHE PROMPTS PAR TH√âMATIQUE**

**ACTUEL**:
```python
# Prompt reconstruit 36 fois (m√™mes instructions de base)
for age, theme, style:
    prompt = self._build_factual_prompt(artwork, rag_context, age, theme, style)
    # Prompt = 2000+ chars, rebuilt each time
```

**‚úÖ OPTIMISATION: Template cache**
```python
class OllamaFactualGenerator:
    def __init__(self):
        self._prompt_templates = {}  # Cache
    
    def _get_prompt_template(self, age, theme, style):
        key = f"{age}_{theme}_{style}"
        if key not in self._prompt_templates:
            # Construire template 1√ó
            self._prompt_templates[key] = self._build_template(age, theme, style)
        return self._prompt_templates[key]
    
    def generate_narration(self, artwork, rag_context, age, theme, style):
        template = self._get_prompt_template(age, theme, style)
        # Juste remplacer variables (title, artist, context)
        prompt = template.format(
            title=artwork['title'],
            artist=artwork['artist'],
            rag_context=rag_context
        )
```

**Gain**: Reconstruction string r√©duite (marginal, ~5% plus rapide)

### **3. BATCH INSERTION PREGENERATIONS**

**ACTUEL**:
```python
# pregeneration_db.py (1 INSERT par narration)
for narration in narrations:
    add_pregeneration(oeuvre_id, age, theme, style, text)  # 1 commit
    # 36 commits = lent
```

**‚úÖ OPTIMISATION: executemany**
```python
def add_pregenerations_batch_optimized(batch_data):
    conn = _connect_postgres()
    cur = conn.cursor()
    try:
        cur.executemany("""
            INSERT INTO pregenerations (oeuvre_id, age_cible, thematique, style_texte, pregeneration_text)
            VALUES (%s, %s, %s, %s, %s)
            ON CONFLICT (oeuvre_id, age_cible, thematique, style_texte)
            DO UPDATE SET pregeneration_text = EXCLUDED.pregeneration_text
        """, batch_data)
        conn.commit()  # 1 seul commit pour 36 narrations
    finally:
        cur.close()
        conn.close()
```

**Gain**: 36 commits ‚Üí 1 commit (~10-15% plus rapide DB writes)

### **4. UTILISER VRAIMENT FAISS (Recommandation future)**

**ACTUEL**:
```python
# ollama_pregeneration_complete.py:88
rag_context = self._build_artwork_rag_context(oeuvre_id, chunks)
# = Concat√®ne TOUS les chunks (pas de recherche)
```

**‚úÖ UTILISATION FAISS (si >10 chunks dans le futur)**:
```python
def _build_filtered_rag_context(self, oeuvre_id, theme):
    # Cr√©er query selon th√©matique
    queries = {
        'technique_picturale': "technique peinture mat√©riaux composition couleurs",
        'biographie': "artiste vie parcours formation influence",
        'historique': "√©poque contexte historique √©v√©nements p√©riode"
    }
    
    query = queries.get(theme, "")
    
    # Rechercher top-3 chunks via FAISS
    top_chunks = self.rag_engine.search_similar_chunks(
        query=query,
        oeuvre_id=oeuvre_id,
        top_k=3,
        threshold=0.3
    )
    
    # Combiner avec chunk 0 (M√âTADONN√âES) toujours
    metadata_chunk = get_artwork_chunks(oeuvre_id)[0]
    context = metadata_chunk['chunk_text'] + "\n\n"
    context += "\n\n".join([c['chunk_text'] for c in top_chunks])
    
    return context
```

**Avantage**: Contexte ultra-cibl√© = meilleure qualit√© narration
**Inconv√©nient**: Risque manquer info importante (pour 5-8 chunks, ALL chunks = safer)

**Recommandation**: **Garder approche actuelle (ALL chunks)** car 5-8 chunks = ~5000 chars (acceptable)

---

## üìà R√âSUM√â OPTIMISATIONS PROPOS√âES

| Optimisation | Gain estim√© | Complexit√© | Priorit√© | Recommandation |
|--------------|-------------|------------|----------|----------------|
| **Parall√©lisation 36 narrations** | **70%** (4.8min ‚Üí 1.5min) | Moyenne | **HAUTE** | ‚úÖ **FAIRE** |
| **Batch embeddings** | 30-50% (embedding phase) | Faible | **MOYENNE** | ‚úÖ Recommand√© |
| **Batch INSERT pregenerations** | 10-15% (save phase) | Faible | MOYENNE | ‚úÖ Recommand√© |
| **Fix TRUNCATE chunk** | √âvite reg√©n inutiles | Faible | **HAUTE** | ‚úÖ **FAIRE** |
| **Cache prompt templates** | 5% | Faible | BASSE | Optionnel |
| **FAISS search filtered** | Variable | Haute | BASSE | ‚ùå Pas pour 5-8 chunks |
| **Add indexes chunk/embeddings** | Acc√©l√®re queries | Faible | MOYENNE | ‚úÖ Recommand√© |

---

## üéØ RECOMMANDATIONS FINALES

### **A. CORRECTIONS IMM√âDIATES**

#### 1. **Fix TRUNCATE chunk CASCADE**
```typescript
// app/api/save-to-db/route.ts ligne 86
// AVANT:
await client.query('TRUNCATE TABLE points, relations, entities, plans, chunk CASCADE')

// APR√àS:
await client.query('TRUNCATE TABLE points, relations, entities, plans CASCADE')
// Chunks g√©r√©s s√©par√©ment par force_regenerate
```

#### 2. **Ajouter indexes DB**
```sql
-- database/init.sql
CREATE INDEX IF NOT EXISTS idx_chunk_oeuvre ON chunk(oeuvre_id);
CREATE INDEX IF NOT EXISTS idx_embeddings_chunk ON embeddings(chunk_id);
```

#### 3. **Batch embeddings creation**
```python
# backend/rag/core/rag_engine_postgres.py
def create_embeddings_for_artwork(self, oeuvre_id: int):
    chunks = get_artwork_chunks(oeuvre_id)
    chunk_texts = [c['chunk_text'] for c in chunks]
    chunk_ids = [c['chunk_id'] for c in chunks]
    
    # Batch encode (1 seul forward pass)
    embeddings = self.model.encode(chunk_texts, batch_size=32, convert_to_numpy=True)
    faiss.normalize_L2(embeddings)
    
    # Batch insert
    values = [(cid, pickle.dumps(emb), self.model_name, emb.shape[0]) 
              for cid, emb in zip(chunk_ids, embeddings)]
    cur.executemany("INSERT INTO embeddings (...) VALUES (%s, %s, %s, %s)", values)
```

### **B. OPTIMISATIONS PERFORMANCE (Phase 2)**

#### 1. **Parall√©lisation g√©n√©ration**
```python
# backend/rag/core/ollama_pregeneration_complete.py
from concurrent.futures import ThreadPoolExecutor

def pregenerate_artwork_parallel(self, oeuvre_id, force_regenerate):
    # Setup RAG 1√ó
    chunks = get_artwork_chunks(oeuvre_id)
    rag_context = self._build_artwork_rag_context(oeuvre_id, chunks)
    
    # G√©n√©rer 36 en parall√®le (8 workers)
    tasks = [(age, theme, style) 
             for age in self.ages 
             for theme in self.themes 
             for style in self.styles]
    
    with ThreadPoolExecutor(max_workers=8) as executor:
        results = list(executor.map(
            lambda t: self._generate_one(oeuvre_id, chunks, rag_context, *t),
            tasks
        ))
    
    # Batch save
    add_pregenerations_batch(results)
```

#### 2. **Batch save pregenerations**
```python
# backend/rag/core/pregeneration_db.py
def add_pregenerations_batch(batch_data):
    """batch_data = [(oeuvre_id, age, theme, style, text), ...]"""
    conn = _connect_postgres()
    cur = conn.cursor()
    try:
        cur.executemany("""
            INSERT INTO pregenerations (...)
            VALUES (%s, %s, %s, %s, %s)
            ON CONFLICT (...) DO UPDATE SET ...
        """, batch_data)
        conn.commit()
    finally:
        cur.close()
        conn.close()
```

### **C. SCALABILIT√â MULTI-MUS√âES (Phase 3)**

#### 1. **Ajouter museum_id**
```sql
ALTER TABLE plans ADD COLUMN museum_id INTEGER DEFAULT 1;
ALTER TABLE oeuvres ADD COLUMN museum_id INTEGER DEFAULT 1;

CREATE INDEX idx_oeuvres_museum ON oeuvres(museum_id);
CREATE INDEX idx_plans_museum ON plans(museum_id);
```

#### 2. **Table param√®tres mus√©e**
```sql
CREATE TABLE museum_settings (
    museum_id SERIAL PRIMARY KEY,
    nom TEXT NOT NULL,
    ages_cibles TEXT[] DEFAULT ARRAY['enfant', 'ado', 'adulte', 'senior'],
    thematiques TEXT[] DEFAULT ARRAY['technique_picturale', 'biographie', 'historique'],
    styles TEXT[] DEFAULT ARRAY['analyse', 'decouverte', 'anecdote'],
    ollama_temperature REAL DEFAULT 0.2,
    walking_speed REAL DEFAULT 0.5,
    narration_wpm INTEGER DEFAULT 90
);
```

#### 3. **G√©n√©rateur dynamique**
```python
class OllamaPregenerationSystem:
    def __init__(self, museum_id: int = 1):
        settings = get_museum_settings(museum_id)
        self.ages = settings['ages_cibles']
        self.themes = settings['thematiques']
        self.styles = settings['styles']
        # Reste identique
```

---

## ‚úÖ VALIDATION FINALE

### **QUESTIONS CL√âS**

**Q1: Est-ce la bonne strat√©gie d'utiliser chunks + embeddings + FAISS?**
**R:** ‚úÖ **OUI**, strat√©gie standard et √©prouv√©e pour RAG. Seul b√©mol: FAISS pas utilis√© actuellement (mais acceptable pour 5-8 chunks).

**Q2: Est-ce scalable pour plusieurs mus√©es?**
**R:** ‚úÖ **OUI**, architecture bien s√©par√©e (plan_id, oeuvre_id). Ajouter museum_id = parfait.

**Q3: Peut-on am√©liorer qualit√©/diversit√©/vitesse?**
**R:** ‚úÖ **OUI**:
- **Qualit√©**: D√©j√† bon (prompts factuels, validation stricte) - filtrage chunks par th√®me = am√©lioration marginale
- **Diversit√©**: D√©j√† bon (36 combinaisons uniques) - ajouter temperature variable selon style = possible
- **Vitesse**: ‚úÖ **Parall√©lisation = gain 70%** (recommand√© fortement)

**Q4: Peut-on r√©utiliser contexte/prompts entre narrations?**
**R:** ‚úÖ **D√©j√† fait pour contexte RAG** (cr√©√© 1√ó, r√©utilis√© 36√ó). Prompts = rebuild 36√ó mais impact faible (5%).

**Q5: Pipeline DB est-elle propre (pas d'orphelins, pas d'√©crasements non voulus)?**
**R:** ‚úÖ **OUI SAUF**:
- ‚ö†Ô∏è TRUNCATE chunk CASCADE = reg√©n inutile (FIX: ne pas truncate chunk)
- ‚úÖ Cascades ON DELETE = propres
- ‚úÖ UNIQUE constraints = pas doublons
- ‚úÖ Orphelins oeuvres g√©r√©s (sauf si pregenerations)

---

## üìã CHECKLIST AVANT TEST

### **Modifications recommand√©es AVANT test**

- [ ] **Fix TRUNCATE chunk** (save-to-db/route.ts ligne 86)
- [ ] **Add indexes** (idx_chunk_oeuvre, idx_embeddings_chunk)
- [ ] **Batch embeddings** (rag_engine_postgres.py)

### **Optimisations APR√àS premier test**

- [ ] **Parall√©lisation 36 narrations** (ThreadPoolExecutor)
- [ ] **Batch save pregenerations** (executemany)
- [ ] **Mesurer temps** (chunks, embeddings, FAISS, LLM)
- [ ] **Tester force_regenerate=true vs false**

### **Scalabilit√© (quand multi-mus√©es)**

- [ ] **Ajouter museum_id** (plans, oeuvres)
- [ ] **Cr√©er museum_settings table**
- [ ] **G√©n√©rateur dynamique** (param√®tres par mus√©e)

---

## üöÄ CONCLUSION

**VOTRE ARCHITECTURE EST SOLIDE ET SCALABLE.**

**Points forts majeurs**:
1. ‚úÖ Chunks s√©mantiques bien structur√©s (7-8 sections th√©matiques)
2. ‚úÖ Embeddings + FAISS = standard RAG (m√™me si FAISS pas utilis√© pour 5-8 chunks)
3. ‚úÖ Database integrity propre (cascades, UNIQUE constraints)
4. ‚úÖ S√©paration plan/≈ìuvres = multi-mus√©es ready
5. ‚úÖ Pregenerations r√©utilisables (ON CONFLICT DO UPDATE)

**Am√©liorations recommand√©es** (par priorit√©):
1. **HAUTE**: Fix TRUNCATE chunk (√©vite reg√©n inutiles)
2. **HAUTE**: Parall√©lisation 36 narrations (gain 70%)
3. **MOYENNE**: Batch embeddings (gain 30%)
4. **MOYENNE**: Batch save pregenerations (gain 10%)
5. **BASSE**: Cache prompts (gain 5%)

**Vous pouvez tester d√®s maintenant**, mais appliquer les **2 fixes HAUTE priorit√©** = gain temps √©norme.

---

**Generated**: 5 Janvier 2026  
**Version**: 1.0 - Audit Architecture Complet

# üéØ PLAN D'ACTION: PIPELINE G√âN√âRATION NARRATIONS

## üìã STRAT√âGIE CHOISIE

### **Timing: √Ä CHAQUE LANCEMENT DE PR√âG√âN√âRATION (pas √† l'upload)**

**Raison**:
- Les m√©tadonn√©es PDF peuvent √™tre am√©lior√©es/corrig√©es apr√®s upload
- Les chunks doivent √™tre cr√©√©schaque fois pour √©viter stale data
- Permet regen forc√©e : `force_regenerate=true` ‚Üí TRUNCATE chunks + embeddings + indices
- Workflow simple et clair

**Flux**:
```
Upload PDF
  ‚Üì
Extraction m√©tadonn√©es (extract-pdf-metadata) ‚Üí sauvegarde oeuvre
  ‚Üì
Clic bouton "G√©n√©rer Narrations" au dashboard
  ‚Üì
Pr√©g√©n√©ration:
  1. Supprimer anciens chunks/embeddings/index (si force_regenerate=true)
  2. Cr√©er chunks s√©mantiques depuis m√©tadonn√©es
  3. Cr√©er embeddings pour chaque chunk
  4. Construire index FAISS
  5. G√©n√©rer 36 narrations avec RAG + Ollama
  6. Sauvegarder pregenerations
```

---

## ‚úÖ COMPOSANTS EXISTANTS

### 1. **Dashboard** ‚úÖ 
- Bouton "G√©n√©rer pour 1 ≈ìuvre" ‚Üí appelle `POST /api/admin/pregenerate-artwork/{oeuvreId}`
- Bouton "G√©n√©rer pour TOUTES" ‚Üí appelle `POST /api/admin/pregenerate-all`
- Affiche stats et liste pr√©g√©n√©rations

### 2. **Routes NextJS** ‚úÖ
- `POST /api/admin/pregenerate-artwork/[oeuvreId]` ‚Üí proxy vers backend
- `POST /api/admin/pregenerate-all` ‚Üí proxy vers backend
- `POST /api/extract-pdf-metadata` ‚Üí extraction PDF (proxy)

### 3. **Backend Python** ‚úÖ
- `ollama_pregeneration_complete.py` ‚Üí orchestration compl√®te
- `chunk_creator_postgres.py` ‚Üí cr√©e chunks depuis m√©tadonn√©es
- `ollama_generator.py` ‚Üí g√©n√®re narrations (ANCIEN - √† remplacer)

---

## üîß AM√âLIORATIONS √Ä FAIRE

### 1. **Remplacer G√©n√©rateur Ancien par Nouveau**
- ‚úÖ Nouveau fichier cr√©√©: `ollama_generator_improved.py`
- ‚ùå Pas encore int√©gr√© dans `ollama_pregeneration_complete.py`

**√Ä faire**:
```python
# Dans ollama_pregeneration_complete.py ligne ~13
# AVANT:
from rag.core.ollama_generator import get_ollama_generator

# APR√àS:
from rag.core.ollama_generator_improved import get_factual_generator as get_ollama_generator
```

### 2. **Optimiser Cr√©ation de Chunks**
**Probl√®me actuel**: Chunks cr√©√©s avec juste les colonnes m√©tadonn√©es  
**Am√©lioration**: Mieux structurer + contextualiser par th√©matique

**Fichier**: `backend/rag/traitement/chunk_creator_postgres.py`

Ajouter:
- Chunks organis√©s par cat√©gorie (technique, biographie, historique)
- Chunks avec titre + contexte pour meilleure pertinence
- Limite longueur chunks (max 500 chars pour mieux matcher)
- Poids/priorit√© des chunks selon pertinence

### 3. **Optimiser Embeddings**
**Fichier**: `backend/rag/core/rag_engine_postgres.py`

V√©rifier:
- Model embedding utilis√© (SentenceTransformer?)
- Batch processing pour parall√©liser
- Caching embeddings d√©j√† cr√©√©s

### 4. **Optimiser Index FAISS**
- V√©rifier construction efficace
- V√©rifier utilisation CPU (pas GPU)
- Tester taille index pour perf

### 5. **V√©rifier Prompts & Contexte**
- V√©rifier contexte RAG bien construit (top chunks pertinents)
- V√©rifier prompts adapt√©s per profil
- V√©rifier pas d'appels redondants

### 6. **Configuration CPU/RAM/Parall√©lisation**
**Ollama params**:
```python
{
    "num_gpu": 0,          # Force CPU
    "num_thread": 8,       # 8 threads
    "num_batch": 1024,     # Batch parallelization
    "num_ctx": 2048,       # Contexte window
    "temperature": 0.2,    # Ultra-factuel
}
```

**Parall√©lisation**:
- G√©n√©rer 36 narrations en parall√®le (non-blocking)
- Utiliser ThreadPoolExecutor ou asyncio
- Max workers = nombre CPU - 1

---

## üöÄ CHECKLIST √Ä COMPL√âTER

### Phase 1: Int√©gration G√©n√©rateur Am√©lior√©
- [ ] Modifier import dans `ollama_pregeneration_complete.py`
- [ ] Tester que le nouveau g√©n√©rateur est appel√©
- [ ] V√©rifier logs mentionnent "OllamaFactualGenerator"

### Phase 2: Am√©lioration Chunks
- [ ] Am√©liorer `chunk_creator_postgres.py` avec meilleure structure
- [ ] Ajouter chunks par th√©matique
- [ ] Tester cr√©ation chunks pour 1 ≈ìuvre

### Phase 3: Optimisation Embeddings & FAISS
- [ ] V√©rifier configuration dans `rag_engine_postgres.py`
- [ ] Tester batch processing
- [ ] V√©rifier utilisation CPU uniquement

### Phase 4: Tests Int√©gration
- [ ] Tester upload PDF
- [ ] Tester extraction m√©tadonn√©es
- [ ] Tester g√©n√©ration 1 narration (time + RAM)
- [ ] Tester g√©n√©ration 36 narrations (parallelis√©)
- [ ] V√©rifier contenu narrations (factuel, pas d'hallucination)

### Phase 5: Reset & Test Complet
- [ ] Nettoyer base de donn√©es
- [ ] Tester flux complet: cr√©er plan ‚Üí ajouter oeuvres ‚Üí upload PDF ‚Üí g√©n√©rer narrations ‚Üí g√©n√©rer parcours

---

## üìä M√âTRIQUES √Ä VALIDER

**Apr√®s g√©n√©ration 1 narration**:
- Temps: < 5 secondes
- Chunks cr√©√©s: 5-8 pour l'≈ìuvre
- Embeddings cr√©√©s: 5-8 (1 par chunk)
- Narration longueur: 150-300 mots
- Narration factuelle: ‚úÖ (pas "peut-√™tre", "Bonjour", etc.)

**Apr√®s g√©n√©ration 36 narrations**:
- Temps total: < 3-4 minutes (avec parall√©lisation)
- CPU usage: 60-80%
- RAM usage: < 8 GB
- Toutes 36 pr√©g√©n√©rations sauvegard√©es
- Variation: ‚úÖ (chaque profil diff√©rent)

**√Ä v√©rifier**:
```sql
-- Chunks cr√©√©s:
SELECT COUNT(*) FROM chunk WHERE oeuvre_id = 1;  -- Doit √™tre 5-8

-- Embeddings cr√©√©s:
SELECT COUNT(*) FROM embeddings e 
JOIN chunk c ON e.chunk_id = c.chunk_id
WHERE c.oeuvre_id = 1;  -- Doit √™tre 5-8

-- Narrations g√©n√©r√©es:
SELECT COUNT(*) FROM pregenerations WHERE oeuvre_id = 1;  -- Doit √™tre 36

-- Contenu narratif:
SELECT pregeneration_text FROM pregenerations WHERE oeuvre_id = 1 LIMIT 1;
-- V√©rifier: pas "Bonjour", pas "peut-√™tre", contient info du PDF
```

---

## ‚ö†Ô∏è POINTS CRITIQUES

1. **Ollama doit tourner** avant de lancer pr√©g√©n√©ration
   - V√©rifier: `curl http://localhost:11434/api/tags`

2. **PostgreSQL doit √™tre accessible**
   - V√©rifier: `docker ps | grep museum-db`

3. **Mod√®le Mistral doit √™tre charg√©**
   - Si pas dispo: `ollama pull mistral`

4. **Force_regenerate=true** supprime les anciennes donn√©es:
   - ‚ö†Ô∏è √Ä utiliser avec pr√©caution
   - Utiliser pour am√©liorer chunks/embeddings/prompts

5. **Pas de GPU disponible**:
   - ‚úÖ Configuration CPU-only dans `ollama_generator_improved.py`
   - Peut √™tre lent pour gros mod√®les

---

## üìù PROCHAINES √âTAPES EXACT

1. **Modifier import** dans `ollama_pregeneration_complete.py`
2. **Am√©liorer chunks** dans `chunk_creator_postgres.py`
3. **V√©rifier/optimiser** `rag_engine_postgres.py`
4. **Test manuel**:
   ```bash
   # Terminal 1: Backend
   cd backend && python -m rag.main_postgres
   
   # Terminal 2: Frontend
   cd .. && npm run dev
   
   # Browser: /admin/dashboard
   # Cr√©er plan + ≈ìuvre + upload PDF + clic "G√©n√©rer"
   ```
5. **V√©rifier BDD**: Chunks, embeddings, narrations cr√©√©s
6. **Reset complet**: Nettoyer base
7. **Test flux**: Complet plan ‚Üí ≈ìuvre ‚Üí PDF ‚Üí narraitons ‚Üí parcours

---

## üéØ OBJECTIF FINAL

Quand tu dis "C'est bon" = syst√®me pr√™t √† tester:
- ‚úÖ G√©n√©rateur factuel int√©gr√©
- ‚úÖ Chunks optimis√©s
- ‚úÖ Embeddings & FAISS fonctionnels
- ‚úÖ Tout optimis√© CPU/RAM
- ‚úÖ Pas d'hallucinations
- ‚úÖ Pr√™t √† r√©initialiser et tester flux complet
